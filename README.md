# *New Visible Watermark Protection Mechanism Based on Information Hiding*

[Paper](https://ieeexplore.ieee.org/document/11095771) / [Newly proposed dataset (LOGO-Multi and LOGO-Full)](https://huggingface.co/datasets/WendellH/Watermark_dataset_LOGO-Full_Multi) / [Other dataset (LOGO-H, LOGO-L, LOGO-Gray)](https://github.com/vinthony/deep-blind-watermark-removal?tab=readme-ov-file#Resources)

# Abstract
With the rise of digital media, protecting image property has become a critical issue. Visible watermarks, once a key tool for copyright protection, have become increasingly vulnerable to removal methods using deep neural networks (DNNs). This poses a significant threat to the ability of visible watermarks to protect image ownership and copyright. To address this increasingly severe challenge, we propose a novel visible watermark protection mechanism based on information hiding. Unlike traditional methods of directly adding perturbations to protected images, we hide adversarial perturbations in watermarked images through a specially designed reversible information exchange (RIE) module, which includes multiple discrete wavelet transform (DWT) and affine coupling blocks. This design can concentrate the perturbations on textured areas of the watermarked images, making them less visually noticeable. Meanwhile, theoretical analysis indicates that the difference between the adversarial image (i.e., the watermarked image after embedding the adversarial perturbation) generated by our method and the watermarked image is completely controllable. To evaluate the proposed mechanism in various scenarios, based on several widely used datasets (i.e., LOGO-Gray, LOGO-H, and LOGO-L), we further synthesize two new datasets, namely LOGO-Multi and LOGO-Full. LOGO-Multi contains images embedded with multiple watermarks, and LOGO-Full contains images embedded with a watermark covering the whole image. Extensive testing on five datasets demonstrates that, compared to the baseline methods, the proposed scheme can greatly improve the visual quality of adversarial images and enhance their capability to resist various watermark removal techniques. Code will be available at https://github.com/Aitchson-Hwang/adversarial_visible_watermarking.

# Citation
### BibTeX
```bibtex
@article{huang2025new,
  title={New Visible Watermark Protection Mechanism Based on Information Hiding},
  author={Huang, Wenhong and Dai, Yunshu and Fei, Jianwei and Huang, Fangjun},
  journal={IEEE Transactions on Information Forensics and Security},
  year={2025},
  volume={20},
  pages={7764-7776},
  doi={10.1109/TIFS.2025.3592572},
  publisher={IEEE}
}
```

### Plain Text
```
W. Huang, Y. Dai, J. Fei, and F. Huang, "New Visible Watermark Protection Mechanism Based on Information Hiding," in IEEE Transactions on Information Forensics and Security, vol. 20, pp. 7764-7776, 2025, doi: 10.1109/TIFS.2025.3592572. keywords: {Watermarking;Perturbation methods;Visualization;Protection;Image restoration;Discrete wavelet transforms;Couplings;Symbols;Media;Data mining;Visible watermark;adversarial attack;watermark removal;copyright protection;data hiding},
```

# Instruction for code
This repository contains the RIE module and the implementation of embedding adversarial perturbations to resist watermark removers using the RIE module. This repository also contains the implementation of the partially visible watermark removal network in the `wm_removers` directory.

## Quick Start
### Install the requirement
```bash
pip install -r requirements.txt
```
### Prepare the dataset
[Newly proposed dataset (LOGO-Multi and LOGO-Full)](https://huggingface.co/datasets/WendellH/Watermark_dataset_LOGO-Full_Multi) / [Other dataset (LOGO-H, LOGO-L, LOGO-Gray)](https://github.com/vinthony/deep-blind-watermark-removal?tab=readme-ov-file#Resources)
### Prepare the pretrained watermark removal models
[SLBR(pretrained on LOGO-Multi dataset)](https://drive.google.com/drive/folders/1fTe1VhCnCCSSaszvDCXey0KBuZc--7i2?usp=sharing)
### Modify the content in example.sh according to your actual situation
```bash
#!/bin/bash
# ================================================================
# Script Name: example.sh
# Description:
#   This script runs the Adversarial Visible Watermarking experiment
#   using the SLBR model (DENet, SplitNet, MNet, etc. are also applicable. 
#        You only need to (or not) add some fields unique to their models. 
#        You can find them in the .sh files in their source code.). 
#   This script launches the training or attack process
#   with customizable parameters such as learning rate, dataset path,
#   and attack configuration.
#
# Usage:
#   bash example.sh
#
# Notes:
#   - Modify the paths below to match your environment.
#   - Requires a CUDA-capable GPU and dependencies from requirements.txt.
#
# Arguments:
#   --epochs             Number of training epochs.
#   --schedule           Learning rate schedule strategy.
#   --lr                 Initial learning rate.
#   --resume             Path to the pretrained watermark removal model checkpoint.
#   --arch               Model architecture to use (e.g., SLBR).
#   -c                   Path to save.
#   --attack_method      Adversarial attack method (e.g., pgd_inn, pgd).
#   --limited-dataset    Whether to use a limited dataset (1 = True).
#   --use_rie            Enable the RIE module to insert perturabtion.
#   --epsilon            Perturbation limit for general adversarial attack (e.g., pgd).
#   --step_alpha         Step size for PGD attack.
#   --stopnum            How many adversairal images to generate.
#   --iters              Number of general attack iterations.
#   --rie_iters          Number of the RIE module iterations.
#   --simage             Whether to save adversarial images.
#   --lambda_p           Loss weight for perceptual loss.
#   --input-size         Input image size.
#   --train-batch        Training batch size.
#   --test-batch         Testing batch size.
#   --use_refine         Enable refinement module, only used for the SLBR model.
#   --base-dir           Path to the dataset root directory.
#   --data               Dataset name (e.g., 'multi', 'full', '10kgray', '10kmid', etc.).
#
# Example:
#   bash example.sh
# ================================================================
```
